# ğŸ“š Resumo de Textos e Livros - LLM Assistant ğŸ¤–

Este projeto Ã© uma aplicaÃ§Ã£o web criada com **Streamlit** ğŸŒ e **Hugging Face Inference API** ğŸ”¥, que permite gerar **resumos de textos** e **pÃ¡ginas de livros** em diversos idiomas ğŸŒ, utilizando um modelo de linguagem (LLM - Large Language Model) para a geraÃ§Ã£o e traduÃ§Ã£o de resumos. O modelo LLM Ã© especializado em resumir textos e traduzi-los para o idioma solicitado pelo usuÃ¡rio. ğŸ“âœ¨

## ğŸš€ Funcionalidades

- **ğŸ“ GeraÃ§Ã£o de Resumos**: O assistente gera resumos concisos de textos ou pÃ¡ginas de livros inseridos pelo usuÃ¡rio.
- **ğŸŒ TraduÃ§Ã£o AutomÃ¡tica**: O modelo traduz o resumo gerado para o idioma escolhido pelo usuÃ¡rio.
- **ğŸ‘¨â€ğŸ’» Interface Interativa**: Criada com **Streamlit**, onde o usuÃ¡rio pode facilmente inserir o texto ou pÃ¡gina e escolher o idioma de saÃ­da para o resumo.

## ğŸ—ï¸ Arquitetura

O cÃ³digo foi desenvolvido utilizando os seguintes conceitos:
- **SOLID**: O cÃ³digo foi estruturado de forma a seguir os princÃ­pios SOLID, com classes e funÃ§Ãµes bem definidas ğŸ’¡.
- **Hugging Face LLM**: O modelo de linguagem Ã© acessado via API do **Hugging Face** ğŸ”‘.
- **Streamlit**: A interface foi construÃ­da com o framework Streamlit para facilitar a interaÃ§Ã£o com o usuÃ¡rio ğŸ’».

## âš™ï¸ PrÃ©-Requisitos

Antes de rodar o projeto, Ã© necessÃ¡rio ter as seguintes ferramentas instaladas:

- Python 3.7 ou superior ğŸ
- `pip` ou `conda` para gerenciar as dependÃªncias ğŸ“¦
- Conta no [Hugging Face](https://huggingface.co) e chave de API para acessar o modelo ğŸ”‘

## ğŸ’» InstalaÃ§Ã£o

### ğŸ–¥ï¸ Windows

1. **Clone o repositÃ³rio**:
   ```bash
   git clone https://github.com/thaleson/AI_summarizes
   cd resumo-textos-llm
   ```

2. **Instale o Python**:
   Baixe e instale o Python 3.7 ou superior a partir de [python.org](https://www.python.org/downloads/) ğŸ§‘â€ğŸ’».

3. **Crie um ambiente virtual** (opcional, mas recomendado):
   ```bash
   python -m venv .venv
   .\.venv\Scripts\activate
   ```

4. **Instale as dependÃªncias**:
   ```bash
   pip install -r requirements.txt
   ```

5. **Defina as variÃ¡veis de ambiente**:
   Crie um arquivo `.env` na raiz do projeto com as seguintes variÃ¡veis:
   ```bash
   API_KEY=<sua-chave-huggingface>
   MODEL_URL=<url-do-modelo>
   ```

6. **Execute o aplicativo**:
   ```bash
   streamlit run main.py
   ```

### ğŸ MacOS / ğŸ§ Linux

1. **Clone o repositÃ³rio**:
   ```bash
   git clone https://github.com/seu-usuario/resumo-textos-llm.git
   cd resumo-textos-llm
   ```

2. **Instale o Python**:
   - Para macOS: Use o [Homebrew](https://brew.sh/) ou baixe do [python.org](https://www.python.org/downloads/) ğŸ.
   - Para Linux: Use o `apt` ou `dnf` para instalar o Python ğŸ§.

3. **Crie um ambiente virtual** (opcional, mas recomendado):
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   ```

4. **Instale as dependÃªncias**:
   ```bash
   pip install -r requirements.txt
   ```

5. **Defina as variÃ¡veis de ambiente**:
   Crie um arquivo `.env` na raiz do projeto com as seguintes variÃ¡veis:
   ```bash
   API_KEY=<sua-chave-huggingface>
   MODEL_URL=<url-do-modelo>
   ```

6. **Execute o aplicativo**:
   ```bash
   streamlit run main.py
   ```

## ğŸ¤– Como Funciona

1. **ğŸ“ GeraÃ§Ã£o de Resumo**: O usuÃ¡rio insere um texto ou uma pÃ¡gina de livro na interface. O assistente gera um resumo conciso e claro do conteÃºdo.
2. **ğŸŒ TraduÃ§Ã£o**: O usuÃ¡rio pode escolher o idioma em que o resumo serÃ¡ gerado. O modelo faz a traduÃ§Ã£o automÃ¡tica para o idioma selecionado.
3. **ğŸ“² ExibiÃ§Ã£o do Resultado**: O resumo traduzido Ã© exibido na interface de forma clara e estruturada.

### âš™ï¸ Exemplo de Fluxo

1. O usuÃ¡rio insere um texto ou pÃ¡gina de livro ğŸ“š.
2. O usuÃ¡rio escolhe o idioma do resumo (exemplo: "InglÃªs") ğŸŒ.
3. O modelo gera o resumo e o traduz para o idioma escolhido ğŸŒ.
4. O resumo gerado Ã© mostrado na interface ğŸ–¥ï¸.

## ğŸ’¡ Detalhes do Modelo LLM

O modelo utilizado para gerar os resumos e traduÃ§Ãµes Ã© um modelo prÃ©-treinado de **Hugging Face**. Este modelo foi treinado para processar e gerar textos de alta qualidade, com uma capacidade especial para resumir grandes volumes de texto e realizar traduÃ§Ãµes automÃ¡ticas.

### ğŸ”§ ConfiguraÃ§Ã£o do LLM

1. **API do Hugging Face**: O modelo Ã© acessado via API do Hugging Face. Para utilizar a API, vocÃª precisa de uma chave de API, que pode ser obtida ao criar uma conta no Hugging Face e gerar a chave atravÃ©s do painel de controle ğŸ”‘.
2. **ParÃ¢metros AjustÃ¡veis**: A aplicaÃ§Ã£o permite ajustar parÃ¢metros como `max_tokens`, `temperature`, e `top_p` para controlar o comportamento das respostas do modelo. Estes parÃ¢metros ajudam a garantir resumos mais curtos, coerentes e precisos ğŸ’¬.

## ğŸ¤ ContribuiÃ§Ãµes

Sinta-se Ã  vontade para contribuir para o projeto! Se vocÃª encontrar um bug ğŸ ou quiser sugerir melhorias ğŸ’¡, crie um **issue** ou envie um **pull request** ğŸš€.

---

